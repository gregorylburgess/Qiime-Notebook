{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "* Transitive alignments are not accurate, find cases where transitive alignments fail.\n",
    "* Can two sequences that do not co-occur in a sample (group) ever be merged together? (Command 14)\n",
    "* Greg didn't get a rabund file at step 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. About\n",
    "This notebook runs through the Mothur MiSeq SOP tutorial found here: http://www.mothur.org/wiki/MiSeq_SOP .\n",
    "\n",
    "# 2. Installation\n",
    "This tutorial requires Qiime and PANDAseq, both of which can be downloaded/installed as directed below.  \n",
    "\n",
    "### Qiime\n",
    "http://qiime.org/install/install.html\n",
    "Qiime suggest using their pre-packaged Virtual Machine image.  This is quite big (4GB), but comes with a ready-to-go configuration.\n",
    "\n",
    "### PANDAseq\n",
    "https://github.com/neufeld/pandaseq/wiki/Installation.\n",
    "PANDAseq doesn't come with Qiime, so you'll need to install it separately.\n",
    "NOTE: Because Qiime uses Ubuntu 12.04, you may have issues calling apt-get update.  In this case, do this instead:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!sudo apt-add-repository ppa:neufeldlab/ppa && sudo apt-get install pandaseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Necessary Files\n",
    "First, we should download the files used in the tutorial.  The below cell does just that.  In total, the zipped files are about 36MB and may take a few minutes to download/unizp.  See http://www.mothur.org/wiki/MiSeq_SOP#Logistics for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is: /home/qiime/Desktop/Qiime_Notebook/qiime_notebook\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "##### Downloads and unzips all tutorial files #######\n",
    "#####################################################\n",
    "\n",
    "import urllib2\n",
    "import zipfile\n",
    "import os\n",
    "from subprocess import call\n",
    "\n",
    "# make a directory for our tutorial, and jump into it\n",
    "root=\"qiime_notebook\"\n",
    "if os.getcwd().split('/')[-1] != root:\n",
    "    if not os.path.isdir(root):\n",
    "        os.mkdir(root)\n",
    "    os.chdir(root)\n",
    "print \"Current working directory is: \" + os.getcwd()\n",
    "\n",
    "# Files to grab,''\n",
    "files = [('https://raw.githubusercontent.com/edamame-course/2014-tutorials/master/misc/QIIMETutorial_Misc/pandaseq_merge.sh',''),\n",
    "         ('http://www.mothur.org/w/images/d/d6/MiSeqSOPData.zip','')]\n",
    "\n",
    "# File Directory names:\n",
    "seq='MiSeq_SOP'\n",
    "    \n",
    "# Grab and unzip the files\n",
    "for url, path in files:\n",
    "    target = url.split('/')[-1]\n",
    "    if not os.path.isfile(target):\n",
    "        resource = urllib2.urlopen(url)\n",
    "        print \"Downloading \" + target + \"...\\n\"\n",
    "        open(target,'wb').write(resource.read())\n",
    "        \n",
    "        if url.split('.')[-1] == '.zip':\n",
    "            print \"Extracting \" + target + \"...\\n\"\n",
    "            zipfile.ZipFile(target).extractall(path)\n",
    "print \"\\nDone!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Commands\n",
    "\n",
    "## 1. Get a list of Read IDs\n",
    "We want to use PANDAseq to handle our paired-end merging, but PANDAseq require that you tell it explicitly which two files to merge.  Notice that the .fastq files in our directory are all named systematically: F3D[day]_S[id]_L001_[L/R]_001.fastq, where [day] is the day the sample was taken, [id] is a sample ID#, and [L/R] is either an L or R denoting a left/right read.  We can take advantage of this systematic naming with a bash script to generate the list of filenames we want to have PANDAseq run.  Our sample dataset includes a list of all the included .fastq files.  This list is called stability.files.  We can use grep to pull out the unique F3D[day]_S[id] combinations.  The following command below will read stability.files, pull out the F3D[day]_S[id] combinations and write them to a text file called SchlossSampleNames.txt.\n",
    "### 1.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>SchlossSampleNames.txt </td><td>A textfile where each line contains the  F3D[day]_S[id] identifier corresponding to file name pairs in stability.files</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat stability.files | grep -oP \"\\t\\K(F.*)(?=_L001_R1_001.fastq)\" > SchlossSampleNames.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  PANDAseq\n",
    "### Goal: Assemble left and right reads.\n",
    "### Options:\n",
    "-f    Forward Read file in fastq format.\n",
    "-r    Reverese Read file in fastq format.\n",
    "-w    File location to write the joined read file.\n",
    "-g    File location to write the log file.\n",
    "-l    Max length for a joined read.  Reads longer than this length will be discarded.\n",
    "-t    Minimum match threshold.  Reads that do not match above this threshold will be discarded.\n",
    "\n",
    "### Usage: \n",
    "pandaseq -f forward_read.fastq -r reverse_read.fastq -w output_file_location -g log_file_location -L length -t minimum_match_%\n",
    "\n",
    "Notice that this one command will merge a pair of files into one long read.  To join 1,000\n",
    "files, we would need 1,000 commands.  Since we don't want to type those commands manually, \n",
    "we should definitely automate it.  The bash script below does just that by reading  SchlossSampleNames.txt, automatically generating the forward, reverse, and output file names, and calling PANDAseq.\n",
    "\n",
    "### 1.1 Output Files:\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>assembledReads.groups     </td><td>  Which sample each sequence belongs to</td></tr>\n",
    "<tr><td>badReads.fasta</td><td> \tContigs thrown out because they don't pass some criterion</td></tr>\n",
    "<tr><td>badReads.qual </td><td>\tQuality of contigs thrown out because they don't pass some criterion</td></tr>\n",
    "<tr><td>assembledReads.fasta </td><td>\tAssembled for and rev sequences</td></tr>\n",
    "<tr><td>assembledReads.qual       </td><td>  Quality assembled for and rev sequences</td></tr>\n",
    "<tr><td>assembledReads.report     </td><td>  Assembly report for each sequence</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!chmod +x pandaseq_merge.sh\n",
    "!./pandaseq_merge.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  summary.seqs(fasta=assembledReads.fasta)\n",
    "Summarizes a fasta file.\n",
    "### 2.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>assembledReads.summary\t</td><td>  For each sequence name, keeps track of length, nbases, homopolymers and dereplication count.</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "summary.seqs(fasta=assembledReads.fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  screen.seqs(fasta=assembledReads.fasta, group=assembledReads.groups, maxambig=0, maxlength=275)\n",
    "Removes sequences that do not match specified parameters.\n",
    "### 3.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>screenedReads.fasta</td><td> \tSequences that contain 0 ambig and are shorter than 275</td></tr>\n",
    "<tr><td>assembledReads.bad.accnos</td><td> \tList of bad sequences and the reason they were discarded, i.e. number of ambigs or len</td></tr>\n",
    "<tr><td>screenedReads.groups\t </td><td> \tFor each sequence, litst the group to which it belongs</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "screen.seqs(fasta=assembledReads.fasta, group=assembledReads.groups, maxambig=0, maxlength=275)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  unique.seqs(fasta=screenedReads.fasta)\n",
    "Dereplicates identical sequences, keeping track of related sequences.\n",
    "### 4.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>screenedReads.names</td><td> \tTab file; for a sequence, list all the sequences that are completely identical</td></tr>\n",
    "<tr><td>screenedReads.unique.fasta</td><td> \tList of unique sequences</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "unique.seqs(fasta=screenedReads.fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  count.seqs(name=screenedReads.names, group=screenedReads.groups)\n",
    "Creates a table counting the abundance of each sequence in each sample (group).\n",
    "### 5.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>screenedReads.count_table</td><td> \tTable where row are unique seqs and cols are sample. Cell represent abundance of seq in samples</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "count.seqs(name=screenedReads.names, group=screenedReads.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.  summary.seqs(fasta=screenedReads.unique.fasta, count=screenedReads.count_table)\n",
    "Summarizes a fasta file.  In this case, summarizing the list of unique sequences and updating their abundance.\n",
    "### 6.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>screenedReads.unique.summary </td><td> \tSubset of sequences that are unique. Only difference with their description in the previous summary is the numSeqs column, which now contains the total number of sequences included into this sequence</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "summary.seqs(fasta=screenedReads.unique.fasta, count=screenedReads.count_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.  pcr.seqs(fasta=silva.bacteria/silva.bacteria.fasta, start=11894, end=25319, keepdots=F, processors=4)\n",
    "Trims the fasta file (in this case the reference DataBase) to the specified region., i.e, 11894 to 25319\n",
    "### 7.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>../silva.bacteria/silva.bacteria.pcr.fasta </td><td> \tThe trimmed fasta file (DB)</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "pcr.seqs(fasta=silva.bacteria/silva.bacteria.fasta, start=11894, end=25319, keepdots=F, processors=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. system(mv silva.bacteria/silva.bacteria.pcr.fasta ref/silva.bacteria/silva.v4.fasta)\n",
    "Renames the file 'silva.bacteria/silva.bacteria.pcr.fasta' to 'silva.bacteria/silva.v4.fasta'\n",
    "### 8.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>silva.bacteria/silva.v4.fasta </td><td> \tThe renamed file</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "system(mv silva.bacteria/silva.bacteria.pcr.fasta silva.bacteria/silva.v4.fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.  align.seqs(fasta=screenedReads.unique.fasta, reference=silva.bacteria/silva.v4.fasta)\n",
    "Align our unique sequences against the reference DataBase\n",
    "### 9.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>screenedReads.unique.align </td><td> \tThe reads alignment file (not including DB seqs)</td></tr>\n",
    "<tr><td>screenedReads.unique.align.report </td><td> \tContains pairwise alignment information for the sequences and their hits. Ex. alignment length, start in query, start in hit, end in query, etc.</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "align.seqs(fasta=screenedReads.unique.fasta, reference=silva.bacteria/silva.v4.fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10.  summary.seqs(fasta=screenedReads.unique.align, count=screenedReads.count_table)\n",
    "Summarizes a fasta file.  In this case, updates the start & stop columns to reflect the new alignment.\n",
    "### 10.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>screenedReads.unique.summary</td><td> \tUpdates the new start and end values for each of the sequence within the context of the larger alignement</td></tr>\n",
    "</table>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "summary.seqs(fasta=screenedReads.unique.align, count=screenedReads.count_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 11.  screen.seqs(fasta=screenedReads.unique.align, count=screenedReads.count_table, summary=screenedReads.unique.summary, start=1968, end=11550, maxhomop=8)\n",
    "Removes sequences with that start after 1968 or end before 11550.  This enables alignment with the database\n",
    "### 11.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>screenedReads.good.count_table</td><td> \t New table with updated counts that show removed sequences</td></tr>\n",
    "<tr><td>unique.align</td><td> \t Alignment file without the removed sequences</td></tr>\n",
    "<tr><td>screenedReads.unique.bad.accnos</td><td>   Sequences that were removed and reason for removal</td></tr>\n",
    "<tr><td>unique.summary</td><td> New summary file without the removed sequences</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "screen.seqs(fasta=screenedReads.unique.align, count=screenedReads.count_table, summary=screenedReads.unique.summary, start=1968, end=11550, maxhomop=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.  filter.seqs(fasta=unique.align, vertical=T, trump=.)\n",
    "Removes gap-only ('-') columns, and any columns containing a '.' from all alignments.\n",
    "### 12.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>filteredReads.fasta</td><td> \t New trimmed alignment without dots or dashes</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "filter.seqs(fasta=unique.align, vertical=T, trump=.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.  unique.seqs(fasta=filteredReads.fasta, count=screenedReads.good.count_table)\n",
    "Filtering in the previous step may have introduced duplicates, dereplicate these and keep track of their counts\n",
    "### 13.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>filteredReads.count_table</td><td> \t New table with updated counts that show dereplicated sequences</td></tr>\n",
    "<tr><td>filteredReads.unique.fasta</td><td> \t New alignment without the replicated sequences</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "unique.seqs(fasta=filteredReads.fasta, count=screenedReads.good.count_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.  pre.cluster(fasta=filteredReads.unique.fasta, count=filteredReads.count_table, diffs=2)\n",
    "Removes sequences with pyrosequencing errors by clustering within groups (samples) sequences that are within 2bp of eachother.\n",
    "### 14.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>preclusteredReads.fasta</td><td>Contains all the clusters representatives</td></tr>\n",
    "<tr><td> preclusteredReads.count_table </td><td> New counts that represent merged, similar (within 2bp) sequences </td></tr>\n",
    "<tr><td>preclusteredReads.F3D0.map  </td><td> Shows the clusters for each sample (group) </td></tr>\n",
    "<tr><td> ...other samples map files </td><td> ... </td></tr>\n",
    "<tr><td> preclusteredReads.F3D9.map </td><td> Shows the clusters for each sample (group) </td></tr>\n",
    " \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "pre.cluster(fasta=filteredReads.unique.fasta, count=filteredReads.count_table, diffs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.  chimera.uchime(fasta=preclusteredReads.fasta, count=preclusteredReads.count_table, dereplicate=t)\n",
    "Removes chimeras from the count files.  Chimeras are still present in the fasa file.\n",
    "### 15.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>  preclusteredReads.uchime.pick.count_table    </td><td>      New count table not including chimeras in counts\n",
    " </td></tr>\n",
    "<tr><td>   preclusteredReads.uchime.chimeras   </td><td> Log of analysis done to find chimeras      </td></tr>\n",
    "<tr><td> preclusteredReads.uchime.accnos     </td><td>    List of chimeras   </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "chimera.uchime(fasta=preclusteredReads.fasta, count=preclusteredReads.count_table, dereplicate=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.  remove.seqs(fasta=preclusteredReads.fasta, accnos=preclusteredReads.denovo.uchime.accnos)\n",
    "Removes chimeras from the fasta files\n",
    "### 16.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>preclusteredReads.pick.fasta</td><td>  New fasta file without the chimeras </td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "remove.seqs(fasta=preclusteredReads.fasta, accnos=preclusteredReads.denovo.uchime.accnos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.  classify.seqs(fasta=preclusteredReads.pick.fasta, count=preclusteredReads.denovo.uchime.pick.count_table, reference=ref/trainset9_032012.pds.fasta, taxonomy=ref/trainset9_032012.pds.tax, cutoff=80)\n",
    "Classifies the samples into Taxae using the training data\n",
    "### 17.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td> preclusteredReads.pick.pds.wang.taxonomy    </td><td>       Taxonomic classfication for each sequence based on the algorithm implemented in  classify.seqs </td></tr>\n",
    "<tr><td> preclusteredReads.pick.pds.wang.tax.summary\n",
    "</td><td>   Summary of how many sequences occur at each lineage. The info is split taxonomic level -- according to taxonomic tree hierarchy.</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "classify.seqs(fasta=preclusteredReads.pick.fasta, count=preclusteredReads.denovo.uchime.pick.count_table, reference=ref/trainset9_032012.pds.fasta, taxonomy=ref/trainset9_032012.pds.tax, cutoff=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18.  remove.lineage(fasta=preclusteredReads.pick.fasta, count=preclusteredReads.denovo.uchime.pick.count_table, taxonomy=preclusteredReads.pick.pds.wang.taxonomy, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota)\n",
    "Removes non-bacterial sequences\n",
    "### 18.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>  preclusteredReads.pick.pds.wang.pick.taxonomy</td><td> The new taxonomy without the undesirable taxe. Number in the taxonomy indicate the posterior \n",
    "probability according to the Wang method   </td></tr>\n",
    "<tr><td>   preclusteredReads.pick.pick.fasta   </td><td>  New fasta alignment file without the undesirable taxa     </td></tr>\n",
    "<tr><td>  preclusteredReads.denovo.uchime.pick.pick.count_table    </td><td>   New counts table without the undesirable taxa    </td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "remove.lineage(fasta=preclusteredReads.pick.fasta, count=preclusteredReads.denovo.uchime.pick.count_table, taxonomy=preclusteredReads.pick.pds.wang.taxonomy, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.  get.groups(fasta=preclusteredReads.pick.pick.fasta, count=preclusteredReads.denovo.uchime.pick.pick.count_table, groups=Mock)\n",
    "Pulls out sequences that belong to the \"Mock\" community.  Creates a separate count table for the selected sequences.\n",
    "### 19.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>  preclusteredReads.pick.pick.pick.fasta   </td><td>  Contains only sequences that belong to the Mock Community     </td></tr>\n",
    "<tr><td>  preclusteredReads.denovo.uchime.pick.pick.pick.count_table   </td><td>    Count for every sequence from mock   </td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "get.groups(fasta=preclusteredReads.pick.pick.fasta, count=preclusteredReads.denovo.uchime.pick.pick.count_table, groups=Mock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.  seq.error(fasta=preclusteredReads.pick.pick.pick.fasta, count=preclusteredReads.denovo.uchime.pick.pick.pick.count_table, reference=MiSeq_SOP/HMP_MOCK.v35.fasta, aligned=F)\n",
    "Computes the error rate associated with misidentification of a sample with known composition (Mock).  Error rate is defined as 1-(Sum of bases in query - Sum of mismatches to reference)/Sum of bases in query.\n",
    "### 20.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>preclusteredReads.pick.pick.pick.error.summary</td><td>   For every sequence in mock, finds it taxonomy and compute difference and error </td></tr>\n",
    "<tr><td>preclusteredReads.pick.pick.pick.error.seq   </td><td>   Expanded cigar version of the match information.    </td></tr>\n",
    "<tr><td>preclusteredReads.pick.pick.pick.error.chimera</td><td>?</td></tr>\n",
    "<tr><td>   preclusteredReads.pick.pick.pick.error.seq.forward   </td><td>  ? Shows the distribution of errors per base in the forward reads (info on F and R can be obtained form the initial files)     </td></tr>\n",
    "<tr><td>    preclusteredReads.pick.pick.pick.error.seq.reverse  </td><td>    ? Shows the distribution of errors per base in the reverse reads (info on F and R can be obtained form the initial files)   </td></tr>\n",
    "<tr><td>   preclusteredReads.pick.pick.pick.error.count   </td><td>   ?? Frequency of the number of error (not including substitutions in the sequences)    </td></tr>\n",
    "<tr><td>   preclusteredReads.pick.pick.pick.error.matrix   </td><td>  Matrix with counts of reqA,refA reqA,refC, reqA,refG, reqA,refT, etc...      </td></tr>\n",
    "<tr><td>   preclusteredReads.pick.pick.pick.error.ref   </td><td>    Shows the alignment of the query against the ref.   </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "seq.error(fasta=preclusteredReads.pick.pick.pick.fasta, count=preclusteredReads.denovo.uchime.pick.pick.pick.count_table, reference=MiSeq_SOP/HMP_MOCK.v35.fasta, aligned=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.  dist.seqs(fasta=preclusteredReads.pick.pick.pick.fasta, cutoff=0.20)\n",
    "Calculates the pairwise distance (mismatches) between all sequences \n",
    "### 21.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>   preclusteredReads.pick.pick.pick.dist   </td><td>    List version of the distance matrix between all the sequences from the mock community   </td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "dist.seqs(fasta=preclusteredReads.pick.pick.pick.fasta, cutoff=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.  cluster(column=preclusteredReads.pick.pick.pick.dist, count=preclusteredReads.denovo.uchime.pick.pick.pick.count_table)\n",
    "Clusters sequences into OTUs using the default (average neighbor) algorithm\n",
    "### 22.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>   preclusteredReads.pick.pick.pick.an.unique_list.list   </td><td>List of clusters based on the dist.seqs list</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "cluster(column=preclusteredReads.pick.pick.pick.dist, count=preclusteredReads.denovo.uchime.pick.pick.pick.count_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23.  make.shared(list=preclusteredReads.pick.pick.pick.an.unique_list.list, count=preclusteredReads.denovo.uchime.pick.pick.pick.count_table, label=0.03)\n",
    "Counts the number of OTUs and their abundance at a specified level (label).\n",
    "### 23.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>   preclusteredReads.pick.pick.pick.an.unique_list.shared   </td><td>    For the chosen label, shows the number of OTUs and their abundance   </td></tr>\n",
    "<tr><td>preclusteredReads.pick.pick.pick.an.unique_list.Mock.rabund  </td><td> ?Same as above without the header??Didn't show up when Greg ran it </td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "make.shared(list=preclusteredReads.pick.pick.pick.an.unique_list.list, count=preclusteredReads.denovo.uchime.pick.pick.pick.count_table, label=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24.  rarefaction.single(shared=preclusteredReads.pick.pick.pick.an.unique_list.shared)\n",
    "Generates intra-sample rarefaction curves using a re-sampling without replacement approach\n",
    "### 24.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td> preclusteredReads.pick.pick.pick.an.unique_list.groups.rarefaction   </td><td>Table with average number of clusters with lower and upper confidence intervals for each subset size of the rarefaction process </td></tr>\n",
    "</table>\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "rarefaction.single(shared=preclusteredReads.pick.pick.pick.an.unique_list.shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25.  remove.groups(count=preclusteredReads.denovo.uchime.pick.pick.count_table, fasta=preclusteredReads.pick.pick.fasta, taxonomy=preclusteredReads.pick.pds.wang.pick.taxonomy, groups=Mock)\n",
    "Removes sequences belonging to a group (in this case, mock) from .fasta, .name, .group, .list, .taxonomy, and .shared files.\n",
    "### 25.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>preclusteredReads.pick.pick.pick.fasta   </td><td>  The new fasta file without the mock sequences</td></tr>\n",
    "<tr><td>    preclusteredReads.denovo.uchime.pick.pick.pick.count_table   </td><td>The mock file without the counts sequences</td></tr>\n",
    "<tr><td>preclusteredReads.pick.pds.wang.pick.pick.taxonomy    </td><td>The taxonomy file without the mock sequences   </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "remove.groups(count=preclusteredReads.denovo.uchime.pick.pick.count_table, fasta=preclusteredReads.pick.pick.fasta, taxonomy=preclusteredReads.pick.pds.wang.pick.taxonomy, groups=Mock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26.  cluster.split(fasta=preclusteredReads.pick.pick.pick.fasta, count=preclusteredReads.denovo.uchime.pick.pick.pick.count_table, taxonomy=preclusteredReads.pick.pds.wang.pick.pick.taxonomy, splitmethod=classify, taxlevel=4, cutoff=0.15)\n",
    "Sorts sequences into bins by taxonomy and clusters within those bins\n",
    "### 26.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>  preclusteredReads.pick.pick.pick.an.unique_list.list    </td><td>   List the clusters at different cutoff values, their abundance and the list of sequences which they are comprised of\n",
    "    </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "cluster.split(fasta=preclusteredReads.pick.pick.pick.fasta, count=preclusteredReads.denovo.uchime.pick.pick.pick.count_table, taxonomy=preclusteredReads.pick.pds.wang.pick.pick.taxonomy, splitmethod=classify, taxlevel=4, cutoff=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.  make.shared(list=preclusteredReads.pick.pick.pick.an.unique_list.list, count=preclusteredReads.denovo.uchime.pick.pick.pick.count_table, label=0.03)\n",
    "Shows the abundance of each OTU in each sample (group), and for all samples.\n",
    "### 27.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>  preclusteredReads.pick.pick.pick.an.unique_list.shared    </td><td> At 0.03 (97% simmiliarity), shows the abundance of each OTU in each sample (group)    </td></tr>\n",
    "<tr><td>  preclusteredReads.pick.pick.pick.an.unique_list.F3D0.rabund    </td><td> The abundance of each OTU in this sample (group)      </td></tr>\n",
    "<tr><td>  ...Other groups    </td><td>   ....    </td></tr>\n",
    "<tr><td>   preclusteredReads.pick.pick.pick.an.unique_list.F3D9.rabund   </td><td>  The abundance of each OTU in this sample (group)       </td></tr>\n",
    "<tr><td>      </td><td>       </td></tr>\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "make.shared(list=preclusteredReads.pick.pick.pick.an.unique_list.list, count=preclusteredReads.denovo.uchime.pick.pick.pick.count_table, label=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28.  classify.otu(list=preclusteredReads.pick.pick.pick.an.unique_list.list, count=preclusteredReads.uchime.pick.pick.pick.count_table, taxonomy=preclusteredReads.pick.pds.wang.pick.pick.taxonomy, label=0.03)\n",
    "Classifies OTUs and counts abundance in each sample.\n",
    "### 28.1 Output Files\n",
    "<table>\n",
    "<hr><td>Output File</td><td>Description</td></hr>\n",
    "<tr><td>   preclusteredReads.pick.pick.pick.an.unique_list.0.03.cons.taxonomy   </td><td>  Map from OTU # to species, with the abundnace of that species</td></tr>\n",
    "<tr><td> preclusteredReads.pick.pick.pick.an.unique_list.0.03.cons.tax.summary</td><td>  Taxonomy of OTUs and their abundance in each group (sample) </td></tr>\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%mothur\n",
    "set.dir(input=./MiSeq_SOP)\n",
    "classify.otu(list=preclusteredReads.pick.pick.pick.an.unique_list.list, count=preclusteredReads.denovo.uchime.pick.pick.pick.count_table, taxonomy=preclusteredReads.pick.pds.wang.pick.pick.taxonomy, label=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"HI\"\n",
    "%\n",
    "%%mothur\n",
    "seq.summary(fasta=assembledReads.fasta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
